\documentclass[a4paper,12pt]{article}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage{minitoc}

\begin{document}

\title{Elasticsearch assignment}
\author{UO258425, Carlos Manrique Enguita \\
UO236405, Daniel Rückert García \\
UO258454, Violeta Ruiz Martínez}
\date{\today}

\maketitle

\tableofcontents

\dosecttoc

\secttoc

\newpage

\section{Exercise 1}
We choose "Rehab" as topic to develop this first exercise.

To recover all the posts related to the topic we do a first query in order to
find the most significant words related to it. To do that we look for the most
significant words in posts that contain the words {\bf Rehab} and {\bf
Rehabilitation}. We perform an aggregation in the selftext field. Whe tried this
first query using three different similarity metrics: Chi square, Google
normalized distance and percentage. Whe have created an index without stopwords
so we perform this first query in this index to get the most optimum results.

\subsection{Percentage}

When using percentage we set the maximum number of significant terms to 100
because it is the one that gets the fewer results. With this metric we get 10
terms where we consider 5 as relevant:
\begin{multicols}{3}
\begin{itemize}
\item Rehabilitation
\item Rehab
\item Rehabs
\item Criminals
\item Librium (a medical drug)
\end{itemize}
\end{multicols}

\subsection{Google normalized distance}
When we use the Google normalized distance we set the maximum number of
significant terms to 20 as this metric and the Chi square get the most number of
results. With this metric we got 20 terms where we consider 9 as relevant:
\begin{multicols}{3}
\begin{itemize}
\item Rehab
\item Rehabilitation
\item Jail
\item Facility
\item Criminals
\item Outpatient
\item Heroin
\item Homicide
\item Detox
\end{itemize}
\end{multicols}

\subsection{Chi square}
When we used the Chi square metric we also set the maximum number of significant
terms to 20 as we did for the Google one. Using this metric we also get 20 terms
and we consider 9 as relevant:
\begin{multicols}{3}
\begin{itemize}
\item Rehab
\item Rehabilitation
\item Detox
\item Alcoholism
\item Sober
\item Drinking
\item Criminals
\item Outpatient
\item Hospital
\end{itemize}
\end{multicols}

After getting the significant terms we perform a second query searching for
these words in the selftext.

\newpage
\section{Exercise 2}
MLT queries do not directly produce a list of significant terms, they produce
however a list of documents including the relevant terms used to perform the
query. This is simlar to how Google produces its search results. As we know GND
uses the documents resturned by google to generate the list of significant
terms.

Therefore, to perform a similar operation to that of GND we just have to do a
query for significant terms over the MLT query in order to get the most
significant terms of those documents.

After performing such operation , we compared the results to those obtained by a
GND query, obtaining a list of 20 significant terms for each query. Comparing
the results, we obtained that 75\% of the significant terms were identical.
However, increasing the number of significant terms to more than 100 reduced
this accuracy down to 40\%.

Results with 20 significant terms:

\includegraphics[width=\textwidth]{./images/image1.jpg}

Results with 150 significant terms:

\includegraphics[width=\textwidth]{./images/image2.jpg}

\newpage
\section{Exercise 3}

To develop this exercise we perform a query pretty similar to the one in the
first exercise, we look for the most significant terms in the \textbf{selftext}
field of the post that match \textit{"prescribed me"}, \textit{"prescr*"}, or
\textit{"antidepressant*"}. We just use this three possible matches because we
noticed that adding too much terms got worse results for us.

In the aggregation we specified a maximum size of 100 and used Google Normalized
Distance as metric because after trying with all of the ones that we used to
develop the previous exercises we noticed that GND was the one that was working
best in this case.

When though we are working upon an index where the stop words have been removed
we added some other words that must not be taken into account as significant
terms in the aggregation, which are words that are usually related to the taking
of a medication such as types of doctors who are usually the ones allowed to
make a prescription, illnesses and symptoms, side effects, or medication types
such as pills, tablets and so on.

After performing this query we end up with a list of a hundred words where some
are medication names and some are not and for that matter we validate it by
using Wikidata.

In order to make this validation automatically we use the MediaWiki API to get
the data from Wikidata. First for each significant term that we have obtained we
perform a first query to Wikidata in order to get all of the entities which name
matches a given significant term. As this can recover more than one result we go
through it getting the code for each of the entities recovered and perform the
last query to Wikidata using that code. This last query recovers all the
information about the entity. In this last step we check if the entity is an
\textit{"instance of"} ("P31") medication("Q12140") ir pharmaceutical product
("q28885102") and if it is we take that result as valid.

After the validation we get a list of 49 medication names which are:

\begin{multicols}{3}
\begin{itemize}
    \item Zoloft
    \item lexapro
    \item amoxicillin
    \item fluexetine
    \item prednisolone
    \item prozac
    \item sertraline
    \item metronidazole
    \item norepinephrine
    \item klonopin
    \item doxycycline
    \item amitriptyline
    \item levofloxacin
    \item escitalopram
    \item hydroxyzine
    \item trazodone
    \item effexor
    \item paroxetine
    \item dexamphetamine
    \item concerta
    \item duloxetine
    \item flagyl
    \item ritalin
    \item buspar
    \item valium
    \item vitamin
    \item lisinopril
    \item clindamycin
    \item intuniv
    \item lamotrigine
    \item atarax
    \item prevacid
    \item fluticasone
    \item cipro
    \item miralax
    \item gabapentin
    \item focalin
    \item methylprednisolone
    \item alprazolam
    \item naproxen
    \item venlafaxine
    \item strattera
    \item cyclobenzaprine
\end{itemize}
\end{multicols}

\newpage
\section{Exercise 4}

The main purpose of this exercise is to obtain a list with the greatest number
of comorbidity factors with respect to alcoholism.

\subsection{Retrieving the Reddit results}

As we cannot use any expert knowledge as a starting point, we have decided to
begin using a multi match query about \textbf{"problem with alcohol"} by
searching the fields selftext, subreddit and title. We take the 10 most relevant
subreddits from this query which are:
\begin{multicols}{3}
\begin{itemize}
    \item stopdrinking
    \item AlAnon
    \item addiction
    \item alcoholism
    \item depression
    \item Anxiety
    \item BipolarReddit
    \item SuicideWatch
    \item alcoholicsanonymous
    \item offmychest
\end{itemize}
\end{multicols}

\subsection{Publish or Perish}

In order to obtain reliable data on the true comorbities of alcoholism,
\textbf{Publish or Perish} tool has been used. It allows us to obtain the main
scientific papers that deal with this topic and are available in Google
academics. Any document that mentions comorbidities of alcoholism seems relevant
to our propouses. After indexing the documents, we export them in a JSON file
called \textbf{PoPAlcoholismComorbidity.json} that will be treated later as
follows:

\begin{enumerate}
    \item  We have realized that the only relevant information is contained in the title,
so we removed anything else from the json objects.
    \item Remove all the titles that are not written in english.
    \item All English stopwords have been removed.
    \item The list of titles has become a list of words
    \item That list is converted to a dictionary [key, value] containing the
        word and the frequency of appearance.
    \item The dictionary is sorted in descending order.
\end{enumerate}




\end{document}
